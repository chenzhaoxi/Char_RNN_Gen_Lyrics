{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\ANACONDA\\envs\\tensorflownt\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import keras  \n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "from keras.utils import plot_model,np_utils  \n",
    "from keras.preprocessing.image import ImageDataGenerator  \n",
    "from keras.models import *  \n",
    "from keras.layers import *  \n",
    "from keras.callbacks import *  \n",
    "from keras import backend as K  \n",
    "import h5py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"cp.txt\"  \n",
    "raw_text = open(filename).read()  \n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))  \n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))  \n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', ':', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '–', '‘', '’']\n"
     ]
    }
   ],
   "source": [
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_chars = len(raw_text)  \n",
    "n_vocab = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocal:  40\n"
     ]
    }
   ],
   "source": [
    "print('vocal: ',n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_length = 16  #how to decide\n",
    "dataX = []  \n",
    "dataY = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, n_chars - seq_length, 1):  \n",
    "    seq_in = raw_text[i:i + seq_length]  \n",
    "    seq_out = raw_text[i + seq_length]  \n",
    "    dataX.append([char_to_int[char] for char in seq_in])  \n",
    "    dataY.append(char_to_int[seq_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23, 26, 26, 22, 1, 12, 30, 1, 30, 19, 16, 1, 29, 30, 12, 28], [26, 26, 22, 1, 12, 30, 1, 30, 19, 16, 1, 29, 30, 12, 28, 29], [26, 22, 1, 12, 30, 1, 30, 19, 16, 1, 29, 30, 12, 28, 29, 0]]\n",
      "[29, 0, 23]\n"
     ]
    }
   ],
   "source": [
    "print(dataX[:3])\n",
    "print(dataY[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  19159\n"
     ]
    }
   ],
   "source": [
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]  \n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))  \n",
    "#normalize\n",
    "X = X / float(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np_utils.to_categorical(dataY)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set heckpoints and save weights\n",
    "#filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"  \n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')  \n",
    "#callbacks_list = [checkpoint]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM1 (LSTM)                 (None, 16, 128)           66560     \n",
      "_________________________________________________________________\n",
      "Droupout1 (Dropout)          (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "LSTM2 (LSTM)                 (None, 16, 128)           131584    \n",
      "_________________________________________________________________\n",
      "Droupout2 (Dropout)          (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 40)                81960     \n",
      "=================================================================\n",
      "Total params: 280,104\n",
      "Trainable params: 280,104\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()  \n",
    "model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2]), return_sequences=True, name='LSTM1'))  \n",
    "model.add(Dropout(0.2, name='Droupout1'))\n",
    "model.add(LSTM(128,input_shape=(X.shape[1], X.shape[2]),return_sequences=True,name='LSTM2')) \n",
    "model.add(Dropout(0.2,name='Droupout2'))\n",
    "model.add(Flatten(name='Flatten'))  \n",
    "model.add(Dense(n_vocab,activation='softmax',name='output'))  \n",
    "\n",
    "adam=keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy']) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import pydot\n",
    "#import graphviz\n",
    "#plot_model(model, to_file='model.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19159/19159 [==============================] - 7s 372us/step\n",
      "epoch=  20 loss=  8.5355e-01 acc=0.76366\n",
      "19159/19159 [==============================] - 7s 383us/step\n",
      "epoch=  40 loss=  2.7769e-01 acc=0.92474\n",
      "19159/19159 [==============================] - 7s 372us/step\n",
      "epoch=  60 loss=  1.0570e-01 acc=0.97260\n",
      "19159/19159 [==============================] - 7s 377us/step\n",
      "epoch=  80 loss=  8.5079e-02 acc=0.97495\n",
      "19159/19159 [==============================] - 7s 365us/step\n",
      "epoch= 100 loss=  7.0698e-02 acc=0.97797\n",
      "19159/19159 [==============================] - 7s 359us/step\n",
      "epoch= 120 loss=  6.7028e-02 acc=0.97823\n",
      "19159/19159 [==============================] - 7s 363us/step\n",
      "epoch= 140 loss=  6.1115e-02 acc=0.98058\n",
      "19159/19159 [==============================] - 7s 342us/step\n",
      "epoch= 160 loss=  6.0273e-02 acc=0.97928\n",
      "19159/19159 [==============================] - 7s 343us/step\n",
      "epoch= 180 loss=  5.6096e-02 acc=0.98084\n",
      "19159/19159 [==============================] - 7s 358us/step\n",
      "epoch= 200 loss=  5.7106e-02 acc=0.98121\n",
      "19159/19159 [==============================] - 7s 362us/step\n",
      "epoch= 220 loss=  5.7126e-02 acc=0.98001\n",
      "19159/19159 [==============================] - 7s 356us/step\n",
      "epoch= 240 loss=  5.1149e-02 acc=0.98111\n",
      "19159/19159 [==============================] - 7s 366us/step\n",
      "epoch= 260 loss=  5.2762e-02 acc=0.98147\n",
      "19159/19159 [==============================] - 7s 364us/step\n",
      "epoch= 280 loss=  5.4200e-02 acc=0.98168\n",
      "19159/19159 [==============================] - 7s 364us/step\n",
      "epoch= 300 loss=  5.0450e-02 acc=0.98231\n",
      "19159/19159 [==============================] - 7s 367us/step\n",
      "epoch= 320 loss=  5.2919e-02 acc=0.98001\n",
      "19159/19159 [==============================] - 7s 364us/step\n",
      "epoch= 340 loss=  4.9781e-02 acc=0.98241\n",
      "19159/19159 [==============================] - 7s 364us/step\n",
      "epoch= 360 loss=  5.4151e-02 acc=0.98225\n",
      "19159/19159 [==============================] - 7s 370us/step\n",
      "epoch= 380 loss=  4.6706e-02 acc=0.98278\n",
      "19159/19159 [==============================] - 7s 368us/step\n",
      "epoch= 400 loss=  4.6344e-02 acc=0.98267\n"
     ]
    }
   ],
   "source": [
    "nit = 20   # number of training iterations\n",
    "nepoch_per_it = 20  # number of epochs per iterations\n",
    "\n",
    "# Loss, accuracy and epoch per iteration\n",
    "loss = np.zeros(nit)\n",
    "acc = np.zeros(nit)\n",
    "epoch_it = np.zeros(nit)\n",
    "\n",
    "# Main iteration loop\n",
    "for it in range(nit):\n",
    "    \n",
    "    # Continue the fit of the model\n",
    "    init_epoch = it*nepoch_per_it\n",
    "    model.fit(X, Y, epochs=nepoch_per_it, batch_size=32,verbose=0)#, callbacks=callbacks_list)  \n",
    "    \n",
    "    # Measure the loss and accuracy on the training data\n",
    "    lossi, acci = model.evaluate(X,Y)\n",
    "    epochi = (it+1)*nepoch_per_it\n",
    "    epoch_it[it] = epochi\n",
    "    loss[it] = lossi\n",
    "    acc[it] = acci\n",
    "    print(\"epoch=%4d loss=%12.4e acc=%7.5f\" % (epochi,lossi,acci))\n",
    "model.save('lyrics_pre.h5')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next(input_array):\n",
    "    x = np.reshape(input_array,(1,seq_length,1))\n",
    "    x = x/float(n_vocab)\n",
    "    y = model.predict(x)\n",
    "    return y\n",
    "\n",
    "def string_to_index(raw_input):\n",
    "    res = []\n",
    "    if len(raw_input)<seq_length:\n",
    "        for i in range(seq_length-len(raw_input)):\n",
    "            res.append(1)\n",
    "    for c in raw_input[-seq_length:]:\n",
    "        res.append(char_to_int[c])\n",
    "    return res\n",
    "\n",
    "def y_to_char(y):\n",
    "    #n = 2\n",
    "    #largest = y.argsort()[0]\n",
    "    #largest = largest[-2:]\n",
    "    #top_n = np.zeros(n)\n",
    "    #for i in range(n):\n",
    "    #    top_n[i]=largest[i]\n",
    "    #np.random.shuffle(top_n)\n",
    "    #c = int_to_char[top_n[0]]\n",
    "    largest = y.argmax()\n",
    "    c = int_to_char[largest]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_article(init, rounds=500):\n",
    "    in_string = init.lower()\n",
    "    for i in range(rounds):\n",
    "        n = y_to_char(predict_next(string_to_index(in_string)))\n",
    "        in_string +=n\n",
    "    return in_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are diamonds taking shape\n",
      "\n",
      "if we’ve only got this life\n",
      "this adventure oh then i\n",
      "and if we’ve only got this life\n",
      "this adventure oh then i\n",
      "and if we’ve only got this life\n",
      "this adventure oh then i\n",
      "and if we’ve only got this life\n",
      "this adventure oh then i\n",
      "and if we’ve only got this life\n",
      "this adventure oh then i\n",
      "and if we’ve only got this life\n",
      "this adventure oh then i\n",
      "and if we’ve only got this life\n",
      "this adventure oh then i\n",
      "and if we’ve only got this life\n",
      "this adventure oh then i\n",
      "and if we’ve only got this life\n",
      "this adventure\n"
     ]
    }
   ],
   "source": [
    "init = \"we are diamonds taking shape\"\n",
    "article = generate_article(init)\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
