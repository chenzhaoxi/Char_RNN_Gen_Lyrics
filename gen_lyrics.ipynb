{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\ANACONDA\\envs\\tensorflownt\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import keras  \n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "from keras.utils import plot_model,np_utils  \n",
    "from keras.preprocessing.image import ImageDataGenerator  \n",
    "from keras.models import *  \n",
    "from keras.layers import *  \n",
    "from keras import backend as K  \n",
    "import h5py \n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"cp.txt\"  \n",
    "raw_text = open(filename).read()  \n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chars to interger vectors: build rnn's input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))  \n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))  \n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '‘', '’', '…']\n"
     ]
    }
   ],
   "source": [
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_chars = len(raw_text)  \n",
    "n_vocab = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocal:  54\n"
     ]
    }
   ],
   "source": [
    "print('vocal: ',n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cut the text in semi-redundant sequences of sqe_length characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_length = 36  #how to decide\n",
    "step = 3\n",
    "dataX = []  \n",
    "dataY = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, n_chars - seq_length, step):  \n",
    "    seq_in = raw_text[i:i + seq_length]  \n",
    "    #seq_out = raw_text[i + seq_length]  \n",
    "    seq_out = raw_text[i+1:i+1+seq_length] \n",
    "    dataX.append([char_to_int[char] for char in seq_in])  \n",
    "    #dataY.append(char_to_int[seq_out])\n",
    "    dataY.append([char_to_int[c] for c in seq_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43, 44, 33, 36, 36, 1, 37, 49, 1, 32, 29, 25, 42, 44, 1, 25, 38, 28, 1, 32, 39, 36, 28, 1, 37, 49, 1, 44, 39, 38, 31, 45, 29, 0, 33, 1], [36, 36, 1, 37, 49, 1, 32, 29, 25, 42, 44, 1, 25, 38, 28, 1, 32, 39, 36, 28, 1, 37, 49, 1, 44, 39, 38, 31, 45, 29, 0, 33, 1, 30, 29, 29], [37, 49, 1, 32, 29, 25, 42, 44, 1, 25, 38, 28, 1, 32, 39, 36, 28, 1, 37, 49, 1, 44, 39, 38, 31, 45, 29, 0, 33, 1, 30, 29, 29, 36, 1, 37]]\n",
      "[[44, 33, 36, 36, 1, 37, 49, 1, 32, 29, 25, 42, 44, 1, 25, 38, 28, 1, 32, 39, 36, 28, 1, 37, 49, 1, 44, 39, 38, 31, 45, 29, 0, 33, 1, 30], [36, 1, 37, 49, 1, 32, 29, 25, 42, 44, 1, 25, 38, 28, 1, 32, 39, 36, 28, 1, 37, 49, 1, 44, 39, 38, 31, 45, 29, 0, 33, 1, 30, 29, 29, 36], [49, 1, 32, 29, 25, 42, 44, 1, 25, 38, 28, 1, 32, 39, 36, 28, 1, 37, 49, 1, 44, 39, 38, 31, 45, 29, 0, 33, 1, 30, 29, 29, 36, 1, 37, 49]]\n"
     ]
    }
   ],
   "source": [
    "print(dataX[:3])\n",
    "print(dataY[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  34404\n"
     ]
    }
   ],
   "source": [
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reshape X to be [samples, time steps, features] , and so do Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " #X = np.reshape(dataX, (n_patterns, seq_length, 1))  \n",
    "#normalize\n",
    "#X = X / float(n_vocab)\n",
    "#Y = np_utils.to_categorical(dataY) \n",
    "X = np.zeros((n_patterns, seq_length, n_vocab), dtype = np.bool)\n",
    "Y = np.zeros((n_patterns, seq_length, n_vocab), dtype=np.bool)\n",
    "#Y = np.zeros((n_patterns, n_vocab), dtype=np.bool)\n",
    "for i, sentence in enumerate(dataX):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char] = 1\n",
    "    #Y[i, dataY[i]] = 1\n",
    "for i, sentence in enumerate(dataY):\n",
    "    for t, char in enumerate(sentence):\n",
    "        Y[i, t, char] = 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set heckpoints and save weights\n",
    "#filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"  \n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')  \n",
    "#callbacks_list = [checkpoint]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build rnn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\envs\\tensorflownt\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  if __name__ == '__main__':\n",
      "D:\\ANACONDA\\envs\\tensorflownt\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, input_shape=(None, 54), return_sequences=True)`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ANACONDA\\envs\\tensorflownt\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From D:\\ANACONDA\\envs\\tensorflownt\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1204: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From D:\\ANACONDA\\envs\\tensorflownt\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, None, 128)         93696     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 128)         131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 54)          6966      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, None, 54)          0         \n",
      "=================================================================\n",
      "Total params: 232,246\n",
      "Trainable params: 232,246\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()  \n",
    "#model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2]), return_sequences=True, name='LSTM1'))  \n",
    "#model.add(Dropout(0.2, name='Droupout1'))\n",
    "#model.add(LSTM(128,input_shape=(X.shape[1], X.shape[2]),return_sequences=False,name='LSTM2')) \n",
    "#model.add(Dropout(0.2,name='Droupout2'))\n",
    "#model.add(Flatten(name='Flatten'))  \n",
    "#model.add(Dense(n_vocab,activation='softmax',name='output')) \n",
    "\n",
    "model.add(LSTM(128, input_dim=n_vocab,return_sequences=True))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(n_vocab))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import pydot\n",
    "#import graphviz\n",
    "#plot_model(model, to_file='model.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "iter =  0\n",
      "----- Generating with seed: \" ooh ooh ooh ooh\n",
      "\n",
      "you and me are flo\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\envs\\tensorflownt\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ooh ooh ooh ooh\n",
      "\n",
      "you and me are floating on a tidal wave together\n",
      "all my heart over that\n",
      "you're the one i love to do i go to fall on me\n",
      "tired you sliming ever cause you here beside me\n",
      "but you mean more meant to know\n",
      "it's no it is friends\n",
      "i'll get a folling all last\n",
      "i call it true\n",
      "i call it magic\n",
      "\n",
      "i saw speed living in perfect day\n",
      "\n",
      "i don't know what houst set love\n",
      "stop out of the day\n",
      "the same stering in high\n",
      "so on this hady nemers t\n"
     ]
    }
   ],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "nit = 1   # number of training iterations\n",
    "nepoch_per_it = 20  # number of epochs per iterations\n",
    "# Main iteration loop\n",
    "for it in range(nit):\n",
    "    # Continue the fit of the model\n",
    "    init_epoch = it*nepoch_per_it\n",
    "    model.fit(X, Y, epochs=nepoch_per_it, batch_size=128,verbose=0)#, callbacks=callbacks_list)  \n",
    "\n",
    "    #Output generated text after each iteration\n",
    "    print('-'*50)\n",
    "    print(\"iter = \",it)\n",
    "    start = random.randint(0, n_chars - seq_length -1)\n",
    "    generated = ''\n",
    "    sentence = raw_text[start:start+seq_length]\n",
    "    generated +=sentence\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, seq_length, n_vocab))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_to_int[char]]=1\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_int = sample(preds[len(sentence)-1])\n",
    "        next_char = int_to_char[next_int]\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:]+next_char\n",
    "    print(generated)\n",
    "           \n",
    "model.save('lyrics_pre.h5')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"you and me\"\n",
      "The generated text is:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\envs\\tensorflownt\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you and me\n",
      "and they're it be saved, lettrees in the kind of pare\n",
      "you don't then lie\n",
      "to the seach coming home;\n",
      "\n",
      "watch your heavy looking for gold\n",
      "in the pope\n",
      "why pood out ifeel never get hurt\n",
      "and me your own politik\n",
      "\n",
      "feeling the ripten watch is just a comy and sen\n",
      "oh and i heard it on a roof, named everything's not gonna stand to go\n",
      "don't believe my morting bout it loud, as mine\n",
      "\n",
      "where do won't see the beaut\n"
     ]
    }
   ],
   "source": [
    "generated = ''\n",
    "sentence = 'you and me'\n",
    "generated +=sentence\n",
    "print('----- Generating with seed: \"' + sentence + '\"')\n",
    "print ('The generated text is:\\n')\n",
    "for i in range(400):\n",
    "    x_pred = np.zeros((1, len(sentence), n_vocab))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0, t, char_to_int[char]]=1\n",
    "    preds = model.predict(x_pred, verbose=0)[0]\n",
    "    next_int = sample(preds[len(sentence)-1])\n",
    "    next_char = int_to_char[next_int]\n",
    "    generated += next_char\n",
    "    sentence = sentence[1:]+next_char\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
