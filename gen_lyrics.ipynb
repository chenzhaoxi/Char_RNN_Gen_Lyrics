{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\ANACONDA\\envs\\tensorflownt\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import keras  \n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "from keras.utils import plot_model,np_utils  \n",
    "from keras.preprocessing.image import ImageDataGenerator  \n",
    "from keras.models import *  \n",
    "from keras.layers import *  \n",
    "from keras import backend as K  \n",
    "import h5py \n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"cp.txt\"  \n",
    "raw_text = open(filename).read()  \n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chars to interger vectors: build rnn's input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))  \n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))  \n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '‘', '’', '…']\n"
     ]
    }
   ],
   "source": [
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_chars = len(raw_text)  \n",
    "n_vocab = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocal:  54\n"
     ]
    }
   ],
   "source": [
    "print('vocal: ',n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cut the text in semi-redundant sequences of sqe_length characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_length = 36  #how to decide\n",
    "step = 3\n",
    "dataX = []  \n",
    "dataY = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, n_chars - seq_length, step):  \n",
    "    seq_in = raw_text[i:i + seq_length]  \n",
    "    seq_out = raw_text[i+1:i+1+seq_length] \n",
    "    dataX.append([char_to_int[char] for char in seq_in])  \n",
    "    #dataY.append(char_to_int[seq_out])\n",
    "    dataY.append([char_to_int[c] for c in seq_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43, 44, 33, 36, 36, 1, 37, 49, 1, 32, 29, 25, 42, 44, 1, 25, 38, 28, 1, 32, 39, 36, 28, 1, 37, 49, 1, 44, 39, 38, 31, 45, 29, 0, 33, 1], [36, 36, 1, 37, 49, 1, 32, 29, 25, 42, 44, 1, 25, 38, 28, 1, 32, 39, 36, 28, 1, 37, 49, 1, 44, 39, 38, 31, 45, 29, 0, 33, 1, 30, 29, 29], [37, 49, 1, 32, 29, 25, 42, 44, 1, 25, 38, 28, 1, 32, 39, 36, 28, 1, 37, 49, 1, 44, 39, 38, 31, 45, 29, 0, 33, 1, 30, 29, 29, 36, 1, 37]]\n",
      "[[44, 33, 36, 36, 1, 37, 49, 1, 32, 29, 25, 42, 44, 1, 25, 38, 28, 1, 32, 39, 36, 28, 1, 37, 49, 1, 44, 39, 38, 31, 45, 29, 0, 33, 1, 30], [36, 1, 37, 49, 1, 32, 29, 25, 42, 44, 1, 25, 38, 28, 1, 32, 39, 36, 28, 1, 37, 49, 1, 44, 39, 38, 31, 45, 29, 0, 33, 1, 30, 29, 29, 36], [49, 1, 32, 29, 25, 42, 44, 1, 25, 38, 28, 1, 32, 39, 36, 28, 1, 37, 49, 1, 44, 39, 38, 31, 45, 29, 0, 33, 1, 30, 29, 29, 36, 1, 37, 49]]\n"
     ]
    }
   ],
   "source": [
    "print(dataX[:3])\n",
    "print(dataY[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  34404\n"
     ]
    }
   ],
   "source": [
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reshape X to be [samples, time steps, features] , and so do Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.zeros((n_patterns, seq_length, n_vocab), dtype = np.bool)\n",
    "Y = np.zeros((n_patterns, seq_length, n_vocab), dtype=np.bool)\n",
    "for i, sentence in enumerate(dataX):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char] = 1\n",
    "for i, sentence in enumerate(dataY):\n",
    "    for t, char in enumerate(sentence):\n",
    "        Y[i, t, char] = 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build rnn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\envs\\tensorflownt\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\ANACONDA\\envs\\tensorflownt\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, input_shape=(None, 54), return_sequences=True)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ANACONDA\\envs\\tensorflownt\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From D:\\ANACONDA\\envs\\tensorflownt\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1204: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From D:\\ANACONDA\\envs\\tensorflownt\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, None, 128)         93696     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 128)         131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 54)          6966      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, None, 54)          0         \n",
      "=================================================================\n",
      "Total params: 232,246\n",
      "Trainable params: 232,246\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()  \n",
    "\n",
    "model.add(LSTM(128, input_dim=n_vocab,return_sequences=True))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(n_vocab))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import pydot\n",
    "#import graphviz\n",
    "#plot_model(model, to_file='model.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "iter =  0\n",
      "----- Generating with seed: \"rong to \n",
      "ask, who does this belong t\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\envs\\tensorflownt\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rong to \n",
      "ask, who does this belong to a place what it is you're talking that outer space and sing to me\n",
      "the spiel waiting for you\n",
      "and if you love me, won't you let me through\n",
      "let me go\n",
      "but then i ever want to fall\n",
      "could have been for i love it when you come over to the heaving of the saint\n",
      "said if i can a believer\n",
      "don’t say it was all yellow\n",
      "\n",
      "you can be any heavy out of the things and one on you\n",
      "oh\n",
      "\n",
      "\n",
      "come stired in my heart i couldn\n",
      "--------------------------------------------------\n",
      "iter =  1\n",
      "----- Generating with seed: \"t's only your imagination\n",
      "it's only \"\n",
      "t's only your imagination\n",
      "it's only your imagination\n",
      "it's only all of the throked it break your heart\n",
      "\n",
      "\n",
      "poolly half if something that my gooh gone for\n",
      "\n",
      "and you say, \"oh, say\n",
      "how come people struggle how come people suffer eyes\n",
      "in the new sun in\n",
      "the more you windo\n",
      "so low \n",
      "didn't believe i'm in\n",
      "i've got to tell you in my loudest tones\n",
      "i'll caurblieldip on the radced\n",
      "be dark felon the thousandse and shorning to do\n",
      "so i wanna live in a \n",
      "--------------------------------------------------\n",
      "iter =  2\n",
      "----- Generating with seed: \"t explain\n",
      "once you'd gone there was \"\n",
      "t explain\n",
      "once you'd gone there was never\n",
      "never an honest word\n",
      "but that was when i ruled the world\n",
      "\n",
      "hear that i could write a roof\n",
      "plater part of the holes\n",
      "\n",
      "ohohoh\n",
      "\n",
      "\n",
      "so it's over\n",
      "this time i know it’s over for wind\n",
      "\n",
      "all the time of your live in a bigged open\n",
      "and i know i was so high as paen\n",
      "we're gonna run dry\n",
      "and darling that's when i decide to go see \n",
      "you cut you never even see me\n",
      "\n",
      "\n",
      "climb up your mountain \n",
      "ninet start in the broun\n",
      "--------------------------------------------------\n",
      "iter =  3\n",
      "----- Generating with seed: \"ve\n",
      "down here where i cannot see so c\"\n",
      "ve\n",
      "down here where i cannot see so close \n",
      "and if you wonder where turning my head out\n",
      "to see what i'm all about\n",
      "keeping my head down\n",
      "to see what it feels like now\n",
      "and i have no doubt\n",
      "one day we're going to get out\n",
      "\n",
      "in we’ll be broken for you\n",
      "you see the world\n",
      "and a mast? \n",
      "i’m miment with some sountrol the mostime i see you \n",
      "\n",
      "cause you're a sky you're going where you get long and dark in your side now\n",
      "go now\n",
      "go now\n",
      "\n",
      "peoping my head o\n",
      "--------------------------------------------------\n",
      "iter =  4\n",
      "----- Generating with seed: \"ht over london today\n",
      "\n",
      "\n",
      "wooh, ooh ooh\"\n",
      "ht over london today\n",
      "\n",
      "\n",
      "wooh, ooh ooh ooh\n",
      "\n",
      "fixing up a car to drive in it again\n",
      "\n",
      "i of all the things you do\n",
      "and it was easy\n",
      "no one ever said it would find a way of letting you see\n",
      "that i'm so ey too \n",
      "and get the line\n",
      "my belly is so full \n",
      "when you feel so tired, but you can’t go wrong\n",
      "\n",
      "brothers and sisters unitize\n",
      "and you are longing to be tamed, singing\n",
      "\n",
      "come out upon that under this weight\n",
      "when i thore \n",
      "and i cannot replace\n",
      "tears st\n"
     ]
    }
   ],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "nit = 5   # number of training iterations\n",
    "nepoch_per_it = 20  # number of epochs per iterations\n",
    "# Main iteration loop\n",
    "for it in range(nit):\n",
    "    # Continue the fit of the model\n",
    "    init_epoch = it*nepoch_per_it\n",
    "    model.fit(X, Y, epochs=nepoch_per_it, batch_size=128,verbose=0)\n",
    "\n",
    "    #Output generated text after each iteration\n",
    "    print('-'*50)\n",
    "    print(\"iter = \",it)\n",
    "    start = random.randint(0, n_chars - seq_length -1)\n",
    "    generated = ''\n",
    "    sentence = raw_text[start:start+seq_length]\n",
    "    generated +=sentence\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, seq_length, n_vocab))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_to_int[char]]=1\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_int = sample(preds[len(sentence)-1])\n",
    "        next_char = int_to_char[next_int]\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:]+next_char\n",
    "    print(generated)\n",
    "           \n",
    "model.save('lyrics_pre.h5')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"tuesday\"\n",
      "The generated text is:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\envs\\tensorflownt\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuesday\n",
      "but in vooles\n",
      "i need a painter stays it's true\n",
      "i'm so run and sills before the holes now\n",
      "it could see it all 'bre the world\n",
      "and they shine way\n",
      "but nothing under the south when you'll never start with the world in mine?\n",
      "and i can’t get down me\n",
      "and in my world\n",
      "all that you shiver that you’re going to be moving at all\n",
      "\n",
      "\n",
      "lovers find me\n",
      "so i turn the new all i want to roll a lifetisnomy of eyes\n",
      "\n",
      "but g\n"
     ]
    }
   ],
   "source": [
    "generated = ''\n",
    "#The seed\n",
    "sentence = 'tuesday'\n",
    "generated +=sentence\n",
    "print('----- Generating with seed: \"' + sentence + '\"')\n",
    "print ('The generated text is:\\n')\n",
    "for i in range(400): ##How long\n",
    "    x_pred = np.zeros((1, len(sentence), n_vocab))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0, t, char_to_int[char]]=1\n",
    "    preds = model.predict(x_pred, verbose=0)[0]\n",
    "    next_int = sample(preds[len(sentence)-1])\n",
    "    next_char = int_to_char[next_int]\n",
    "    generated += next_char\n",
    "    sentence = sentence[1:]+next_char\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
